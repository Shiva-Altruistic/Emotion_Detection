<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>Live Emotion Detection</title>

<style>
body {
  margin: 0;
  min-height: 100vh;
  background: #020617;
  display: flex;
  flex-direction: column;
  align-items: center;
  font-family: Arial;
  color: white;
}

h2 {
  margin: 20px 0;
  color: #38bdf8;
}

.container {
  display: flex;
  gap: 50px;
  margin-top: 20px;
}

.video-box {
  position: relative;
}

video, canvas {
  width: 320px;
  height: 320px;
  border-radius: 14px;
  border: 3px solid #38bdf8;
}

canvas {
  position: absolute;
  top: 0;
  left: 0;
}

.panel {
  background: #0f172a;
  padding: 25px;
  border-radius: 16px;
  width: 320px;
  text-align: center;
}

.emoji {
  font-size: 60px;
  margin-bottom: 10px;
}

.stat {
  margin: 8px 0;
}
</style>
</head>

<body>

<h2>Live Webcam Emotion Detection</h2>

<div class="container">

  <div class="video-box">
    <video id="video" autoplay playsinline></video>
    <canvas id="canvas" width="320" height="320"></canvas>
  </div>

  <div class="panel">
    <div id="emoji" class="emoji">üòê</div>
    <div class="stat">Emotion: <span id="emotion">Waiting...</span></div>
    <div class="stat">Confidence: <span id="confidence">--%</span></div>
    <div class="stat">Accuracy: <span id="accuracy">--%</span></div>
    <div class="stat" id="reply">Waiting for face...</div>
  </div>

</div>

<script>
const video = document.getElementById("video");
const canvas = document.getElementById("canvas");
const ctx = canvas.getContext("2d");

navigator.mediaDevices.getUserMedia({ video: true })
  .then(stream => video.srcObject = stream);

async function sendFrame() {
  if (!video.videoWidth) return;

  // Capture frame
  ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
  const img = canvas.toDataURL("image/jpeg");

  // Send to backend
  const r = await fetch(
    "https://emotion-detection-2-b56x.onrender.com/predict",
    {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({ image: img })
    }
  );

  const d = await r.json();

  // Update UI safely
  document.getElementById("emoji").innerText = d.emoji || "üòê";
  document.getElementById("emotion").innerText = d.emotion || "No Face";
  document.getElementById("confidence").innerText =
    (d.confidence ?? "--") + "%";
  document.getElementById("accuracy").innerText =
    (d.accuracy ?? "--") + "%";
  document.getElementById("reply").innerText =
    d.reply || "Waiting...";

  // Redraw frame
  ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

  // Draw face box
  if (d.face) {
    const [x, y, w, h] = d.face;
    ctx.strokeStyle = "lime";
    ctx.lineWidth = 3;
    ctx.strokeRect(x, y, w, h);
  }
}

// Run every 900 ms
setInterval(sendFrame, 900);
</script>


</body>
</html>
